---
title: "Classification"
author: "Samuel Twenhafel"
date: "02/24/2025"
---

**Abstract:**

This is a technical blog post of **both** an HTML file *and* [.qmd file](https://raw.githubusercontent.com/cd-public/D505/refs/heads/master/hws/src/classify.qmd) hosted on GitHub pages.

# 0. Quarto Type-setting

-   This document is rendered with Quarto, and configured to embed an images using the `embed-resources` option in the header.
-   If you wish to use a similar header, here's is the format specification for this document:

``` email
format: 
  html:
    embed-resources: true
```

# 1. Setup

**Step Up Code:**

```{r}
sh <- suppressPackageStartupMessages
sh(library(tidyverse))
sh(library(caret))
sh(library(tidytext))
sh(library(SnowballC)) 
sh(library(pROC))      
sh(library(glmnet))
data(stop_words)
wine <- readRDS(gzcon(url("https://github.com/cd-public/D505/raw/master/dat/pinot.rds")))
```

# 2. Logistic Concepts

Why do we call it Logistic Regression even though we are using the technique for classification?

> [**TODO**]{style="color:red;font-weight:bold"}: *We call it Logistic Regression even though we are using the technique for classification because these models do not give us a true or false answer about whther our prediction was right or not, there is a cut off point that corresponds to a specific class.*

# 3. Modeling

We train a logistic regression algorithm to classify a whether a wine comes from Marlborough using:

1.  An 80-20 train-test split.
2.  Three features engineered from the description
3.  5-fold cross validation.

We report Kappa after using the model to predict provinces in the holdout sample.

```{r}
names(wine)[names(wine) == 'id'] = 'id'

desc_to_words <- function(df, omits) { 
  df %>%
    unnest_tokens(word, description) %>%
    anti_join(stop_words) %>% # get rid of stop words
    filter(!(word %in% omits))
}

words <- desc_to_words(wine, c("wine","pinot","vineyard"))

words_to_stems <- function(df) { 
  df %>%
    mutate(word = wordStem(word))
}

stems <- words_to_stems(words)

filter_by_count <- function(df, j) { 
  df %>%
    count(id, word) %>% 
    group_by(id) %>% mutate(exists = (n>0)) %>% ungroup %>% 
    group_by(word) %>% 
    mutate(total = sum(n)) %>% 
    filter(total > j)
}

pivoter <- function(words, df) {
  words %>%
    pivot_wider(id_cols = id, names_from = word, values_from = exists, values_fill = list(exists=0)) %>% 
    right_join(select(df,id,province)) %>% 
    drop_na() %>% 
    select(-id)
}

wine_words <- function(df, j, stem) { 

  words <- desc_to_words(df, c("wine","pinot","vineyard"))
  
  if (stem) {
    words <- words_to_stems(words)
  }
  
  words <- filter_by_count(words, j)

  pivoter(words, df)
}

wino <- wine_words(wine, 1000, F)

wino %>% 
  head(10) %>% 
  select(1:5, province)

wino <- wino %>% 
  mutate(marlborough = factor(province=="Marlborough")) %>%
  select(-province)

set.seed(505)
wine_index <- createDataPartition(wino$marlborough, p = 0.80, list = FALSE)
train <- wino[ wine_index, ]
test <- wino[-wine_index, ]
table(train$marlborough)

control = trainControl(method = "cv", number = 5)
get_fit <- function(df) {
  train(marlborough ~ .,
        data = df, 
        trControl = control,
        method = "glm",
        family = "binomial",
        maxit = 5) # speed it up - default 100
}
fit <- get_fit(train)

fit
```

The Kappa for this model which was trying to predict whether or not the wines came from Marlborough was 0.38.

# 4. Binary vs Other Classification

What is the difference between determining some form of classification through logistic regression versus methods like $K$-NN and Naive Bayes which performed classifications.

> [**TODO**]{style="color:red;font-weight:bold"}: *The difference between classifications through logistic regressions and methods that preform classifications is that the the logistic regressions will give you a probability of what class the predicted item is and the classifications will come back telling you what type of class the predicted item is based off of the model.*

# 5. ROC Curves

We can display an ROC for the model to explain your model's quality.

```{r}
#You can find a tutorial on ROC curves here: https://towardsdatascience.com/understanding-the-roc-curve-and-auc-dd4f9a192ecb/
prob <- predict(fit, newdata = test, type = "prob")[,2]
myRoc <- roc(test$marlborough, prob)
plot(myRoc)
auc(myRoc)
```

> [TODO]{style="color:red;font-weight:bold"}: *The dashed line under the ROC curve indicates a random guess, and to the left of that line are better classifications and the area under the curve indicates the correctness of the model. The area under the curve for this model was 0.90, which is 0.40 better than just random guessing.*
